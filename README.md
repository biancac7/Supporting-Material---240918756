# Automated Gleason Grading Pipeline

This project implements an end-to-end pipeline for automated Gleason grading of prostate cancer histology slides. It is designed to be run from a main Jupyter Notebook that orchestrates all steps from data preprocessing to model training and evaluation.

## Project Structure

This folder contains the main notebook, the Python source code package, and the Optuna experiment database. The necessary data and outputs generated by the pipeline are downloaded from the drive when the notebook is run.

The final structure of the Code folder will be:

```
Code/
├── automated_gleason_grading_analysis_notebook.ipynb  # The main notebook used to visualise all of the results.
|
├── gleason_data/                                      # This folder contains the raw, zipped image and annotation mask files.
|   ├── Maps1_T.zip                                    # Annotation masks for pathologist 1.
|   ├── Maps2_T.zip                                    # Annotation masks for pathologist 2.
|   ├── Maps3_T.zip                                    # Annotation masks for pathologist 3.
|   ├── Maps4_T.zip                                    # Annotation masks for pathologist 4.
|   ├── Maps5_T.zip                                    # Annotation masks for pathologist 5.
|   ├── Maps6_T.zip                                    # Annotation masks for pathologist 6.
|   └── Train Imgs.zip                                 # Annotated histology slides.
│
├── gleason_src/                                       # Main source code package for the project.
│   ├── __init__.py                                    # Makes 'gleason_src' a Python package.
│   ├── analysis.py                                    # Analyses Optuna study results using surrogate models.
│   ├── config.py                                      # Reconstructs the best model configuration from an Optuna study.
│   ├── evaluator.py                                   # Defines and calculates performance metrics for model evaluation.
│   ├── losses.py                                      # Implements custom, composable loss functions for model training.
│   ├── models_utils.py                                # Provides helper functions for building and wrapping models.
│   ├── optuna_objective.py                            # Defines the objective function and main loop for Optuna hyperparameter optimisation.
│   ├── pipeline.py                                    # Orchestrates the preprocessing, training, and evaluation workflows.
│   ├── pspnet.py                                      # Defines the core PSPNet model architecture and GPU-based data augmentations.
│   ├── preprocessing.py                               # Handles all data ingestion, cleaning, and preparation into an HDF5 file.
│   ├── speed.py                                       # A utility to set PyTorch/CUDA flags for optimal performance.
│   ├── trainer.py                                     # Encapsulates the core training and validation loop logic.
│   ├── utils.py                                       # Contains general-purpose helper functions used across the project.
│   └── visualisations.py                              # Generates all plots and visual reports for analysis and evaluation.
│
├── gleason_output/                           # Root directory for all generated outputs.
|   ├── datasets/                             # Contains the processed HDF5 dataset.
|   │   └── gleason_dataset.h5
|   │
|   ├── models/                               # Contains any saved models.
|   │   └── best-model-from-search/           # A folder for the best model from the training runs.
|   │       ├── evaluation/                   # Results from evaluating the model on the test set.
|   |       |   └── disagreement_visuals/
|   |       |   |   ├── disagreement_sample_41.png
|   |       |   |   ├── disagreement_sample_17.png
|   |       |   |   └── disagreement_sample_11.png
|   |       |   |
|   │       │   ├── confusion_matrix.png
|   │       │   ├── detailed_results.pkl
|   │       │   ├── best_williams_predictions_sample_18.png
|   │       │   ├── best_williams_predictions_sample_22.png
|   │       │   ├── best_williams_predictions_sample_34.png
|   │       │   ├── best_williams_predictions_sample_37.png
|   │       │   ├── best_williams_predictions_sample_39.png
|   │       │   ├── best_williams_predictions_sample_4.png
|   |       |   ├── extremes_gleason_dice_worst.png
|   |       |   ├── extremes_williams_index_worst.png
|   |       |   ├── extremes_uncertainty.png
|   │       │   ├── summary.json
|   │       │   └── summary.png
|   │       │
|   │       ├── best_model.pth                # The saved model weights.
|   │       ├── config.json                   # The hyperparameters used for this run.
|   │       └── training_curves.png           # Plot of training/validation loss.
|   │
|   ├── visualisations/                       # Contains data-level visualisations from preprocessing.
|   │   ├── pathologist_agreement.png
|   │   └── pathologist_reliability.png
|   |
|   ├── metadata.json                         # Holds essential metadata about the processed Gleason dataset.
|   |
|   └── optuna_exports/                       # Contains the excel file with all of the Optuna experiment results
|       └── gleason_hpo_trials.xlsx
|
└── gleason_study.db                          # The SQLite database used by Optuna to store trial results.
```

## How To Run

This project does not use an executable file to run the source code. Instead, a main Jupyter notebook is used to run the end-to-end pipeline.

# Running the analysis notebook on Visual Studio Code

1. Download the zip file through GitHub: Press on Code -> Download ZIP.
2. Open the Code folder in Visual Studio Code.
3. Open the automated_gleason_grading_analysis_notebook.ipynb, and press on 'Run All'.

This notebook only contains the results and visualisations of the project. The full notebook can be accessed through Google Colaboratory.

# Running the experiment notebook directly through Google Colaboratory

1.  Navigate to the this link: https://colab.research.google.com/drive/1y41M2PNC1JulzOpa3Su1bXSgK6Yt0KLG#scrollTo=50XZXOd6ULHh. This should open the notebook in Google Colaboratory.
2.  Select a GPU runtime if available.
3.  Run all cells.

The notebook will sequentially execute the entire pipeline:

- **Data Download & Preprocessing:** It will unzip the raw data and process it into the `gleason_output/datasets/gleason_dataset.h5` file (or use the existing gleason_dataset.h5 file, if it was presaved).
- **Hyperparameter Optimisation:** It will run an Optuna study to find the best model hyperparameters, storing results in `gleason_output/gleason_study.db` (the study number is set to 0 by default, so it will only load the experiments from the current saved database).
- **Final Model Training:** It will train the best model configuration found during the search (or use the saved weights if they already exist).
- **Evaluation:** It will evaluate the final model on the test set and save all results and visualisations to the `gleason_output/models/` directory.

**Troubleshooting Download:** If `gdown` fails, you can download the `gleason_data` and `gleason_output` folders manually from [this Google Drive link](https://drive.google.com/drive/folders/1o4N8B5Sv4uNQr4RyiRyK7W9ZHLPIZ-0B?usp=drive_link).
